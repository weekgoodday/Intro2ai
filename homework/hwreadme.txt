hw1：作业一是全局搜索算法。 原版作业见homework1_original，任务要求见 hw1/README.txt 分N皇后和最短路径问题。
运行环境：
C++是程序在Ubuntu18.04，gcc9.4.0运行（本身是7.5.0但hsc师兄顺便就配好了）。python是在Ubuntu18.04,python3.8运行（本来都想在ubuntu18.04运行，但ubuntu18.04自带7.5.0版的gcc报错，貌似gcc8以上版本才OK）。

N皇后问题：
python/c++都需要运行，但都直接写好了，注释输出、点个运行就可以（hw1/python/queens_bfs_dfs.py），比较宽度优先、广度优先搜索时间空间就行。
最短路径问题：
我用的python版本。要求完成一致代价搜索（已经实现在hw1/python/algorithm/uniform_cost_search.py）、贪心搜索、A*搜索

N皇后搜索问题建模：
每行为树的一层，上一层有N个位置作为节点，向下发展，广搜即先探索完上一层的状态（可放置的位置），再向下，直到最后一行valid或者已经不行即切断。valid的路径就输出。

评价：皇后问题没什么意思，浪费时间整理。

最短路径问题：
比较一致代价（dijkstra）、贪心、A*搜索算法在罗马尼亚寻径问题（见.png）的效果。
只运行python，读代码要花点时间，总之估值是负的g或h或g+h，越大越好，稍微修改代码即可。

hw2：作业二是局部搜索算法，相比全局搜索，通过启发函数加速搜索，时间复杂度大大减小，但不保证一定搜到解。
且有的算法不一定n越大，搜索越慢，总体趋势是正相关，但更看运气
运行环境： 很坑，为了作业统一标准，要求必须用C++，我习惯python。
还是N皇后问题。
爬山法：
分三个选择方式 第一更优选择、最大估值选择和轮盘赌选择。
评估的是全局的冲突
状态估值函数h(n)=1/(n^conflicts数)，要求值达到1，也就是conflicts为0才停。（当然有找不到更优后继状态而失败，直接重启就是了）
模拟退火：
爬山+随机游走（等概率向周围邻居移动，增加探索）：通过温度值来控制往估值差状态探索的概率，
刚开始温度高，探索概率大，跳出局部极值；随着时间推移，温度下降，探索概率小，达到最优。
t=1/n*exp(n-t/16/n)（当然可以也自己设置）  选择状态时更优或者探索概率exp-(|d|/t) 就跳转了
遗传：
比较没道理的算法。用-conflicts（负的互相能攻击的皇后对数）作为适应度，每次就选最大的两个杂交变异
这个每代搜的其实挺快的，但是n一大，很可能靠杂交变异搜不到解，不是n越大，搜索越慢，总体趋势是正相关，但更看运气
冲突最小：
先每行随机位置放皇后，然后一行行操作，通过选择算法选一行的皇后放在该行冲突最小的地方，不断重复直至没有冲突。
有可能找不到解，但实际max selection一般都可以找到，且快，first（完全随机选一行）不一定行。
与爬山法的区别是评估的是某一个皇后的冲突，一次选择只有n种。

hw3：
再一次证明了这学期做过的最错误的决策之一就是为了和同学一起，退了引论选了基础，作业是真雷啊！
读了一下代码
本来想改不要每个state重建树，也不要每次都随机simulate，但改起来太麻烦了。
有需要卷的同学可以重新实现一下它的MTCs，能保留以前探索过的值，每次simulate都利用值信息选择而不是都随机，
输入json大概长这样{"requests":[{"forced_x":1,"forced_y":2,"x":-1,"y":-1},{"x":3,"y":7}],"responses":[{"x":1,"y":2}]}
没啥意思，真浪费时间。最后交了个baseline+线性探索系数（一开始大后来小），摆了。

hw4：
很不巧，我刚选过李老师2022秋开的强化学习课，第四次作业就是这门课前两次作业的浓缩版，直接在Intro2ai/homework/hw4/去年强化学习的作业1和2 找对应问题的代码即可。
btw，井字棋实现的应该是RL book第10页那个简单的状态价值的更新（与动作无关），应该是temporal-difference td 学习方法，当时是让X赢，改成让O赢就可以。 偷懒的，直接把tictactoe.hpp里的PLAYNAME给改了就可以。

hw5:
numpy手工实现反向传播完成mnist数字分类+pytorch版的实现
作业比较繁杂的要求：
分训练集验证集测试集，需要选取验证集上表现最好的模型参数用于测试，并在测试集上达到94%与98%的acc。
直接在验证集和测试集上跑 反正达到acc就行，交的是acc曲线图（理论上曲线图只能是验证集的）。
1、手工实现
需要一些数学推导，我直接实现的是每batch_size*input_size的输入与反向传播（与一个一个行输入有细微的差别）。
2、pytorch实现
这对大四老狗来说太简单了，加了一些optimizer scheduler的奇技淫巧，让acc达标了。

hw6:
配环境应该比较花时间，寒武纪的手册没弄明白最后在我的服务器上跑了。
1、cifar10的网络搭建
直接CSDN上找了一个最简单的CNN（就四层CNN+三层全连接）就可以使acc达到80%以上：
https://blog.csdn.net/sgfsfgs/article/details/126261298
还有一些更深的，或者加个直连ResBlock的实现可以达到更高的acc，有兴趣的话可以试试。
100epoch训起来需要一些时间。好像我们助教要求申请延迟的同学要在验证集上测取最好的模型，然后再去测试集上跑
（但是 pytorch的cifar10 dataloader没有验证集，我只好自己魔改cifar10的dataset了，因为要从指定路径找这个VisionDataset的实现，这套代码大概率没什么可迁移性）
2、人脸识别
非常的麻烦，看源码根本不知道在干什么，要怎么样用才能完成作业要求，非常差的作业布置形式。好在助教补了一个视频说明：
https://meeting.tencent.com/v2/cloud-record/share?id=aeef4a8c-2eb3-43ea-a059-8396f24064f3&from=3
傻了，助教重新传了作业包，补上了几个文件，我是小丑。。。
只要自己找一些图片按照imgs_celebrity下的文件格式命名跑一遍程序就可以了。

hw7:
GAN生成伪造人脸
每处只要补一行代码，这种作业形式大四老狗太喜欢了，这门课逐渐变得推荐起来了？（虽然这1个G的图片数据集传起来比较费事
事实上这里DCGAN的实现和pytorch tutorial一样：
https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#
https://blog.csdn.net/disanda/article/details/102981996

hw8:
手写LSTM进行imdb分类（貌似是电影情感分类），可以用nn.Linear 
找了一下没找到现成的，但通过公式实现四个Linear确实结果和官方一模一样，运行速度上远远不如官方LSTM类，应该做了很多优化。
实现难点在维度concate的统一 h_t c_t 都是(batch,hidden_size) x, y是(batch,length,in_embedding) 最后给y按长度平均，后续全连接到[32,2]二分类
另外这只是单层单向的LSTM 双向可能会有不一样。
学通LSTM四步（作业到第二步）：
1、最基本的RNN与LSTM六个公式
2、LSTM h c x y维度与多层和时序两个维度
3、RNN与LSTM的反向传播优化
4、双向LSTM GRU变体