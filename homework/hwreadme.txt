hw1：作业一是全局搜索算法。 原版作业见homework1_original，任务要求见 hw1/README.txt 分N皇后和最短路径问题。
运行环境：
C++是程序在Ubuntu18.04，gcc9.4.0运行（本身是7.5.0但hsc师兄顺便就配好了）。python是在Ubuntu18.04,python3.8运行（本来都想在ubuntu18.04运行，但ubuntu18.04自带7.5.0版的gcc报错，貌似gcc8以上版本才OK）。

N皇后问题：
python/c++都需要运行，但都直接写好了，注释输出、点个运行就可以（hw1/python/queens_bfs_dfs.py），比较宽度优先、广度优先搜索时间空间就行。
最短路径问题：
我用的python版本。要求完成一致代价搜索（已经实现在hw1/python/algorithm/uniform_cost_search.py）、贪心搜索、A*搜索

N皇后搜索问题建模：
每行为树的一层，上一层有N个位置作为节点，向下发展，广搜即先探索完上一层的状态（可放置的位置），再向下，直到最后一行valid或者已经不行即切断。valid的路径就输出。

评价：皇后问题没什么意思，浪费时间整理。

最短路径问题：
比较一致代价（dijkstra）、贪心、A*搜索算法在罗马尼亚寻径问题（见.png）的效果。
只运行python，读代码要花点时间，总之估值是负的g或h或g+h，越大越好，稍微修改代码即可。

hw2：作业二是局部搜索算法，相比全局搜索，通过启发函数加速搜索，时间复杂度大大减小，但不保证一定搜到解。
且有的算法不一定n越大，搜索越慢，总体趋势是正相关，但更看运气
运行环境： 很坑，为了作业统一标准，要求必须用C++，我习惯python。
还是N皇后问题。
爬山法：
分三个选择方式 第一更优选择、最大估值选择和轮盘赌选择。
评估的是全局的冲突
状态估值函数h(n)=1/(n^conflicts数)，要求值达到1，也就是conflicts为0才停。（当然有找不到更优后继状态而失败，直接重启就是了）
模拟退火：
爬山+随机游走（等概率向周围邻居移动，增加探索）：通过温度值来控制往估值差状态探索的概率，
刚开始温度高，探索概率大，跳出局部极值；随着时间推移，温度下降，探索概率小，达到最优。
t=1/n*exp(n-t/16/n)（当然可以也自己设置）  选择状态时更优或者探索概率exp-(|d|/t) 就跳转了
遗传：
比较没道理的算法。用-conflicts（负的互相能攻击的皇后对数）作为适应度，每次就选最大的两个杂交变异
这个每代搜的其实挺快的，但是n一大，很可能靠杂交变异搜不到解，不是n越大，搜索越慢，总体趋势是正相关，但更看运气
冲突最小：
先每行随机位置放皇后，然后一行行操作，通过选择算法选一行的皇后放在该行冲突最小的地方，不断重复直至没有冲突。
有可能找不到解，但实际max selection一般都可以找到，且快，first（完全随机选一行）不一定行。
与爬山法的区别是评估的是某一个皇后的冲突，一次选择只有n种。
hw3：
再一次证明了这学期做过的最错误的决策之一就是为了和同学一起，退了引论选了基础，作业是真雷啊！
读了一下代码
本来想改不要每个state重建树，也不要每次都随机simulate，但改起来太麻烦了。
有需要卷的同学可以重新实现一下它的MTCs，能保留以前探索过的值，每次simulate都利用值信息选择而不是都随机，
输入json大概长这样{"requests":[{"forced_x":1,"forced_y":2,"x":-1,"y":-1},{"x":3,"y":7}],"responses":[{"x":1,"y":2}]}
没啥意思，真浪费时间。最后交了个baseline+线性探索系数（一开始大后来小），摆了。
hw4：
很不巧，我刚选过李老师2022秋开的强化学习课，第四次作业就是这门课前两次作业的浓缩版，直接在Intro2ai/homework/hw4/去年强化学习的作业1和2 找对应问题的代码即可。
btw，井字棋实现的应该是RL book第10页那个简单的状态价值的更新（与动作无关），应该是temporal-difference td 学习方法，当时是让X赢，改成让O赢就可以。 偷懒的，直接把tictactoe.hpp里的PLAYNAME给改了就可以。